{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2890c2-4b50-420f-8d35-5ee89619ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "127e6cdd-ca95-49dd-9808-06083cee9b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters 1115394\n"
     ]
    }
   ],
   "source": [
    "# read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(f\"length of dataset in characters {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87bbab0c-d93c-4c24-a18f-d47bf30b268b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f3db6b2-2b37-4b7d-8e48-4b9324aa3daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413955e5-5387-407f-8e5d-b6e288d953a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars)}\n",
    "itos = { i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    " \n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "090b28d6-4a95-4ce9-9cf0-4f715fa65941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46], [47], [47], [1], [58], [46], [43], [56], [43]]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(encode, \"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db3c214d-8f0b-43ad-bd26-3ea8379f85ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Using a lambda function with map to square each number\n",
    "squared_numbers_map_object = map(lambda x: x * x, numbers)\n",
    "\n",
    "print(list(squared_numbers_map_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c01b2e2-465c-4b48-959e-e952f923826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import tiktoken\n",
    "    enc = tiktoken.get_encoding(\"gpt2\")\n",
    "    print(enc.n_vocab)\n",
    "    enc.encode(\"hii there\")\n",
    "# GPT trades of the code book size and the length of sequence\n",
    "# tiktoken book ranges from 0 to 50256, hii there len is 3 instead 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6e71837-376b-41ee-b631-df6d2d04c097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # use PyTorch\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[0:1000]) # the 1000 characters we looked at earlier will to the GPT look like thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "495a773e-3ccf-4a6f-8f9c-0e006208793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7bde444-cd12-49e3-88b2-dc45959f0a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]\n",
    "# in the case of 18, 47 comes next\n",
    "# in the case of 18, 47, ... 56 comes next\n",
    "# in the case of 18, 46, 56, ... 57 comes next\n",
    "# ...\n",
    "# 8 training cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8633edd7-7509-411b-b954-e89b5ca0a494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the targe is 47\n",
      "when input is tensor([18, 47]) the targe is 56\n",
      "when input is tensor([18, 47, 56]) the targe is 57\n",
      "when input is tensor([18, 47, 56, 57]) the targe is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the targe is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the targe is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the targe is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the targe is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the targe is {target}\")\n",
    "# context size varies, so that transformer is used to see block of different sizes\n",
    "# transformer is not able to handle sequence longer than block size. As it has never seen it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "95876a3d-ebbb-4d64-bc7c-28a64745f6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "target:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "--------\n",
      "when input is tensor([24]) the target is 43\n",
      "when input is tensor([24, 43]) the target is 58\n",
      "when input is tensor([24, 43, 58]) the target is 5\n",
      "when input is tensor([24, 43, 58,  5]) the target is 57\n",
      "when input is tensor([24, 43, 58,  5, 57]) the target is 1\n",
      "when input is tensor([24, 43, 58,  5, 57,  1]) the target is 46\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46]) the target is 43\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46, 43]) the target is 39\n",
      "when input is tensor([44]) the target is 53\n",
      "when input is tensor([44, 53]) the target is 56\n",
      "when input is tensor([44, 53, 56]) the target is 1\n",
      "when input is tensor([44, 53, 56,  1]) the target is 58\n",
      "when input is tensor([44, 53, 56,  1, 58]) the target is 46\n",
      "when input is tensor([44, 53, 56,  1, 58, 46]) the target is 39\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39]) the target is 58\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39, 58]) the target is 1\n",
      "when input is tensor([52]) the target is 58\n",
      "when input is tensor([52, 58]) the target is 1\n",
      "when input is tensor([52, 58,  1]) the target is 58\n",
      "when input is tensor([52, 58,  1, 58]) the target is 46\n",
      "when input is tensor([52, 58,  1, 58, 46]) the target is 39\n",
      "when input is tensor([52, 58,  1, 58, 46, 39]) the target is 58\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58]) the target is 1\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58,  1]) the target is 46\n",
      "when input is tensor([25]) the target is 17\n",
      "when input is tensor([25, 17]) the target is 27\n",
      "when input is tensor([25, 17, 27]) the target is 10\n",
      "when input is tensor([25, 17, 27, 10]) the target is 0\n",
      "when input is tensor([25, 17, 27, 10,  0]) the target is 21\n",
      "when input is tensor([25, 17, 27, 10,  0, 21]) the target is 1\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1]) the target is 54\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1, 54]) the target is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallerl?\n",
    "block_size = 8 # what is maximum context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of input x and targets y\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix  = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    # print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('target:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print('--------')\n",
    "\n",
    "for b in range(batch_size): # batch_dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23918aa1-eff1-4500-8fed-e7083c056930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[295, 753,  15,  10, 834],\n",
       "        [ 90, 212, 120, 297, 286]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(1000, (2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b4ebd9da-3663-42b4-a50f-3957f31e003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our input to transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "20bfbb3e-146d-4ad4-90f8-5c7ddffa3d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.6305,  0.7277,  1.3488],\n",
      "        [-0.1396,  0.2858,  0.9651],\n",
      "        [-2.0371,  0.4931, -1.2435],\n",
      "        [-0.1680,  0.1260, -1.5627],\n",
      "        [-1.1601, -0.3348,  0.1526],\n",
      "        [ 0.3843,  1.3091,  0.4645],\n",
      "        [ 1.6455, -0.8030,  1.3514],\n",
      "        [-0.2759, -1.7097, -0.0826],\n",
      "        [-0.0495, -1.4480,  1.4516],\n",
      "        [-1.5103,  0.8212, -0.2115]], requires_grad=True)\n",
      "tensor([[1, 2, 4, 5],\n",
      "        [4, 3, 2, 9]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1396,  0.2858,  0.9651],\n",
       "         [-2.0371,  0.4931, -1.2435],\n",
       "         [-1.1601, -0.3348,  0.1526],\n",
       "         [ 0.3843,  1.3091,  0.4645]],\n",
       "\n",
       "        [[-1.1601, -0.3348,  0.1526],\n",
       "         [-0.1680,  0.1260, -1.5627],\n",
       "         [-2.0371,  0.4931, -1.2435],\n",
       "         [-1.5103,  0.8212, -0.2115]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# below is an example of embedding: which converts 0-9 integer to (1,3) vector\n",
    "# embedding of size (10, 3) create 10 tensors of size 3\n",
    "# embedding(2) then reads the 2nd tensor of the embedding size (1, 3)\n",
    "embedding = nn.Embedding(10, 3)\n",
    "print(embedding.weight)\n",
    "input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n",
    "print(input)\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "89a0152a-0ad9-4df0-9b2a-99ff28bccff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        #each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        # The token embedding table is vocab_size by vocab_size\n",
    "       #  Parameter containing:\n",
    "       #  tensor([[-0.9873, -0.1692, -1.7186,  ...,  0.4657, -1.2951,  0.0595],\n",
    "       #  [-1.1337,  0.4521, -2.1238,  ..., -1.6573, -0.8691, -0.9001],\n",
    "       #  [ 0.2113,  1.1337, -1.1722,  ..., -0.6102,  2.3405,  0.6097],\n",
    "       #  ...,\n",
    "       #  [ 0.3448, -0.6760, -0.2725,  ..., -0.7113, -0.6573, -1.6034],\n",
    "       #  [ 0.4921, -0.2105,  0.2333,  ..., -0.2867,  0.2278, -1.6450],\n",
    "       #  [-1.1449, -1.7441,  0.5990,  ...,  0.8644,  0.2535, -0.9051]],\n",
    "       # requires_grad=True)\n",
    "       # for example, char (1) after embedding gives [-1.1337,  0.4521, -2.1238,  ..., -1.6573, -0.8691, -0.9001]\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C) ---batch by time by channel\n",
    "        # (B, T, C) = (8, 4, 65) we will black out these rows ranges them in 8,4,65\n",
    "        # because idx(x) has shape of 4*8, after embedding, it has size of 4*8*65\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            # cross entropy requires logits to have a shape of B(4), C(65), T(8)\n",
    "            logits = logits.view(B*T, C) # squence 4 by 8 by 65 into 32 by 65\n",
    "            # print(logits)\n",
    "            targets = targets.view(B*T)\n",
    "            # print(targets)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is x size (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the prediction\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # (B, T, C) becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sampel from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled indexs to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B,  T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m.forward(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(idx[0].tolist()))\n",
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ea9f380f-9d7d-4912-8645-6435b5c3b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Pytorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3) # general learning rate is 1e-4, but for simple model it can be faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbebaa-810f-4fb8-9505-165ca5faace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    # print(xb)\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True) # zeroing out grad in previous step\n",
    "    loss.backward()  #get new gradient for all parameters\n",
    "    optimizer.step() #use the gradient to update the parameter\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d152d72-25cb-428a-9402-18d0fb4738da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "G Yerposhedamede: my the gherfan'sthea mstl folfe wer d by-\n",
      "'d bl hol we t thowhavat INayenchequre\n",
      "S:\n",
      "Cowis ang alawhepevecadunde? my ay homean:\n",
      "ho g terongod D hofe Hes umeso ger theallatcouse wert my, athy, mes ins, AROfin, mye asth.\n",
      "MICA f mumateterd t e p for t ptwe bor hethther shyo he owimaldizes mond w, ougr! t caphincy ou trvesirorutle d lu galactinug foulimsteirve mite.\n",
      "Whiow herelpoureory ithit; t to---gr whomy, I 'lefanowigir e mourge od sothodyote\n",
      "M: ou, llkipathrss, d ngead ilif a\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe0585-4292-4836-a5d4-efef15a45dc4",
   "metadata": {},
   "source": [
    "## The mathmetical trick in self-attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "de8337bf-5696-488f-bfbb-29ee6d250e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1808, -0.0700],\n",
      "         [-0.3596, -0.9152],\n",
      "         [ 0.6258,  0.0255],\n",
      "         [ 0.9545,  0.0643],\n",
      "         [ 0.3612,  1.1679],\n",
      "         [-1.3499, -0.5102],\n",
      "         [ 0.2360, -0.2398],\n",
      "         [-0.9211,  1.5433]],\n",
      "\n",
      "        [[ 1.3488, -0.1396],\n",
      "         [ 0.2858,  0.9651],\n",
      "         [-2.0371,  0.4931],\n",
      "         [ 1.4870,  0.5910],\n",
      "         [ 0.1260, -1.5627],\n",
      "         [-1.1601, -0.3348],\n",
      "         [ 0.4478, -0.8016],\n",
      "         [ 1.5236,  2.5086]],\n",
      "\n",
      "        [[-0.6631, -0.2513],\n",
      "         [ 1.0101,  0.1215],\n",
      "         [ 0.1584,  1.1340],\n",
      "         [-1.1539, -0.2984],\n",
      "         [-0.5075, -0.9239],\n",
      "         [ 0.5467, -1.4948],\n",
      "         [-1.2057,  0.5718],\n",
      "         [-0.5974, -0.6937]],\n",
      "\n",
      "        [[ 1.6455, -0.8030],\n",
      "         [ 1.3514, -0.2759],\n",
      "         [-1.5108,  2.1048],\n",
      "         [ 2.7630, -1.7465],\n",
      "         [ 1.4516, -1.5103],\n",
      "         [ 0.8212, -0.2115],\n",
      "         [ 0.7789,  1.5333],\n",
      "         [ 1.6097, -0.4032]]])\n"
     ]
    }
   ],
   "source": [
    "# consider the folloing toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape\n",
    "print(x)\n",
    "# the 8 tokens do not talk to each other, but we want them to talk to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6c892057-09bf-458c-8f54-9679969d3561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1808, -0.0700],\n",
      "         [-0.0894, -0.4926],\n",
      "         [ 0.1490, -0.3199],\n",
      "         [ 0.3504, -0.2238],\n",
      "         [ 0.3525,  0.0545],\n",
      "         [ 0.0688, -0.0396],\n",
      "         [ 0.0927, -0.0682],\n",
      "         [-0.0341,  0.1332]],\n",
      "\n",
      "        [[ 1.3488, -0.1396],\n",
      "         [ 0.8173,  0.4127],\n",
      "         [-0.1342,  0.4395],\n",
      "         [ 0.2711,  0.4774],\n",
      "         [ 0.2421,  0.0694],\n",
      "         [ 0.0084,  0.0020],\n",
      "         [ 0.0712, -0.1128],\n",
      "         [ 0.2527,  0.2149]],\n",
      "\n",
      "        [[-0.6631, -0.2513],\n",
      "         [ 0.1735, -0.0649],\n",
      "         [ 0.1685,  0.3348],\n",
      "         [-0.1621,  0.1765],\n",
      "         [-0.2312, -0.0436],\n",
      "         [-0.1015, -0.2855],\n",
      "         [-0.2593, -0.1630],\n",
      "         [-0.3015, -0.2293]],\n",
      "\n",
      "        [[ 1.6455, -0.8030],\n",
      "         [ 1.4985, -0.5395],\n",
      "         [ 0.4954,  0.3420],\n",
      "         [ 1.0623, -0.1802],\n",
      "         [ 1.1401, -0.4462],\n",
      "         [ 1.0870, -0.4071],\n",
      "         [ 1.0430, -0.1299],\n",
      "         [ 1.1138, -0.1641]]])\n"
     ]
    }
   ],
   "source": [
    "# we want x[b, t] = mean_{i<=t} x[b,i[\n",
    "xbow = torch.zeros(B, T, C)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0) #0 dimension is the time dimension\n",
    "print(xbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "03a5bbe3-d5d1-4ade-8233-3c382f466116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.ones(3, 3)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, 1, keepdim = True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b  # matrix multiplication:  3*3 by 3*2 = 3*2\n",
    "print('a=')\n",
    "print(a)\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d9786549-bbe5-4f33-9fa6-2a13b3306315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1808, -0.0700],\n",
      "         [-0.0894, -0.4926],\n",
      "         [ 0.1490, -0.3199],\n",
      "         [ 0.3504, -0.2238],\n",
      "         [ 0.3525,  0.0545],\n",
      "         [ 0.0688, -0.0396],\n",
      "         [ 0.0927, -0.0682],\n",
      "         [-0.0341,  0.1332]],\n",
      "\n",
      "        [[ 1.3488, -0.1396],\n",
      "         [ 0.8173,  0.4127],\n",
      "         [-0.1342,  0.4395],\n",
      "         [ 0.2711,  0.4774],\n",
      "         [ 0.2421,  0.0694],\n",
      "         [ 0.0084,  0.0020],\n",
      "         [ 0.0712, -0.1128],\n",
      "         [ 0.2527,  0.2149]],\n",
      "\n",
      "        [[-0.6631, -0.2513],\n",
      "         [ 0.1735, -0.0649],\n",
      "         [ 0.1685,  0.3348],\n",
      "         [-0.1621,  0.1765],\n",
      "         [-0.2312, -0.0436],\n",
      "         [-0.1015, -0.2855],\n",
      "         [-0.2593, -0.1630],\n",
      "         [-0.3015, -0.2293]],\n",
      "\n",
      "        [[ 1.6455, -0.8030],\n",
      "         [ 1.4985, -0.5395],\n",
      "         [ 0.4954,  0.3420],\n",
      "         [ 1.0623, -0.1802],\n",
      "         [ 1.1401, -0.4462],\n",
      "         [ 1.0870, -0.4071],\n",
      "         [ 1.0430, -0.1299],\n",
      "         [ 1.1138, -0.1641]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow = torch.zeros(B, T, C)\n",
    "for b in range(B):\n",
    "    xbow[b] = wei @ x[b]\n",
    "xbow2 = wei @ x # size: (T by T) @ (B by T by C) -> (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "print(xbow2)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b37d3221-eaf2-494e-a8bd-cfcce8e0804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1808, -0.0700],\n",
      "         [-0.0894, -0.4926],\n",
      "         [ 0.1490, -0.3199],\n",
      "         [ 0.3504, -0.2238],\n",
      "         [ 0.3525,  0.0545],\n",
      "         [ 0.0688, -0.0396],\n",
      "         [ 0.0927, -0.0682],\n",
      "         [-0.0341,  0.1332]],\n",
      "\n",
      "        [[ 1.3488, -0.1396],\n",
      "         [ 0.8173,  0.4127],\n",
      "         [-0.1342,  0.4395],\n",
      "         [ 0.2711,  0.4774],\n",
      "         [ 0.2421,  0.0694],\n",
      "         [ 0.0084,  0.0020],\n",
      "         [ 0.0712, -0.1128],\n",
      "         [ 0.2527,  0.2149]],\n",
      "\n",
      "        [[-0.6631, -0.2513],\n",
      "         [ 0.1735, -0.0649],\n",
      "         [ 0.1685,  0.3348],\n",
      "         [-0.1621,  0.1765],\n",
      "         [-0.2312, -0.0436],\n",
      "         [-0.1015, -0.2855],\n",
      "         [-0.2593, -0.1630],\n",
      "         [-0.3015, -0.2293]],\n",
      "\n",
      "        [[ 1.6455, -0.8030],\n",
      "         [ 1.4985, -0.5395],\n",
      "         [ 0.4954,  0.3420],\n",
      "         [ 1.0623, -0.1802],\n",
      "         [ 1.1401, -0.4462],\n",
      "         [ 1.0870, -0.4071],\n",
      "         [ 1.0430, -0.1299],\n",
      "         [ 1.1138, -0.1641]]])\n"
     ]
    }
   ],
   "source": [
    "# version 3: use softmax\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T, T) # how much each token in the past should be used\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # token in future cannot talk to the past \n",
    "wei = F.softmax(wei, dim=1)\n",
    "# print(wei)\n",
    "xbow3 = wei @ x\n",
    "print(xbow3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26446767-d9c5-495d-8389-f9a51400a118",
   "metadata": {},
   "source": [
    "- every single node at each position will emit two vectors: query & key\n",
    "  - query vector: is what I am looking for\n",
    "  - what do I contain\n",
    "- Do a dot product between keys and querys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f2b82bbb-37bc-4278-9c53-dfa670922254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channel\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias = False)\n",
    "query = nn.Linear(C, head_size, bias = False)\n",
    "value = nn.Linear(C, head_size, bias = False)\n",
    "k = query(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1)  # (B, T, 16) @ (B, 16, T) = (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v # (B, T, T) @ (B, T, 16) --> (B, T, 16)\n",
    "\n",
    "# out = wei @ x # (B, T, T) @ (B, T, C) --> (B, T, C)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8522891-bc9d-4caa-84da-4982fabcb9f9",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "* Attention is a communication mechasim. Can be seen as nodes in a directed graph looking at each other and aggregating\n",
    "* There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7493f1b0-b24d-4fcf-8e8e-fa05f57ee759",
   "metadata": {},
   "source": [
    "# Layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fc6dbf01-1f19-4f04-91e4-41e6e420de7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3842e-09)\n",
      "tensor(1.0000)\n",
      "tensor([ 0.1335, -0.1059, -0.3824, -0.9127,  0.5583, -0.0147,  0.8721,  0.0223,\n",
      "         0.3057,  1.0758, -1.3277, -0.5261,  0.1862, -0.2680, -0.9184,  1.4341,\n",
      "         1.2485, -0.1724,  0.2337,  0.8822, -1.9837,  0.4317,  1.3804,  0.5251,\n",
      "         0.0812, -1.5308, -1.1465, -0.3587,  0.3884, -0.8043,  1.4153,  2.3556,\n",
      "        -0.6721, -0.2789,  0.9252,  0.0769,  0.1121,  1.0434, -1.1406, -0.3239,\n",
      "        -0.5236, -0.9210,  0.4828, -1.4660, -1.1900,  0.5068, -0.6093, -0.7013,\n",
      "         1.5317, -0.8056,  1.2509, -0.3025, -1.4813,  1.9701,  2.5984, -1.7063,\n",
      "         1.3466, -1.4808,  0.7448, -0.2410,  0.7044,  1.4245,  1.4975, -0.4240,\n",
      "        -0.8357,  0.5316, -0.0882, -0.1007, -0.5135,  0.4055, -0.2847, -1.0579,\n",
      "         1.8786, -0.5517,  0.1736,  0.6263, -1.4009,  0.8257,  0.0989,  0.1786,\n",
      "         2.3378, -1.2072,  0.9257,  0.4917, -1.5602, -1.2520,  0.6199, -0.2263,\n",
      "         0.2902, -0.3654,  0.4152, -0.7706, -0.4390, -0.4562, -0.9948, -0.4299,\n",
      "        -1.6303, -1.3422, -0.1971,  0.8795])\n"
     ]
    }
   ],
   "source": [
    "class BatchNorm1d:\n",
    "\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        xmean = x.mean(1, keepdim=True) # batch mean\n",
    "        xvar = x.var(1, keepdim=True) # batch variance\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return (self.gamma, self.beta)\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = BatchNorm1d(100)\n",
    "x = torch.randn(32, 100)\n",
    "x = module(x)\n",
    "x.shape\n",
    "print(x[0,:].mean())\n",
    "print(x[0,:].var())\n",
    "print(x[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b7fc63cc-1134-4ae1-b0a7-85ef14f88441",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embedding_tb = nn.Embedding(8, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "98bbe972-667c-437d-892f-7475471a1208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(8, 32)\n"
     ]
    }
   ],
   "source": [
    "print(position_embedding_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9221e48d-cb14-473d-985d-bc0036149672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 4, 5, 2, 4, 6, 4, 4],\n",
      "        [4, 1, 1, 2, 0, 4, 5, 0],\n",
      "        [5, 0, 2, 4, 4, 3, 5, 0],\n",
      "        [0, 7, 7, 1, 3, 6, 7, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(0,8, (4,8))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "59aea50e-e3aa-4664-a32a-c8e47dde7532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6421,  0.8266, -0.3646,  ..., -0.6845,  0.7134,  0.5298],\n",
       "         [-0.6013, -0.0996, -1.2311,  ...,  0.7546,  0.4145,  1.3664],\n",
       "         [-0.0462, -1.6457, -0.6960,  ...,  0.0916,  1.5164, -0.4389],\n",
       "         ...,\n",
       "         [-0.6421,  0.8266, -0.3646,  ..., -0.6845,  0.7134,  0.5298],\n",
       "         [-0.6013, -0.0996, -1.2311,  ...,  0.7546,  0.4145,  1.3664],\n",
       "         [-0.6013, -0.0996, -1.2311,  ...,  0.7546,  0.4145,  1.3664]],\n",
       "\n",
       "        [[-0.6013, -0.0996, -1.2311,  ...,  0.7546,  0.4145,  1.3664],\n",
       "         [-0.7150, -0.0476,  0.5230,  ..., -1.4120,  1.7361,  1.8350],\n",
       "         [-0.7150, -0.0476,  0.5230,  ..., -1.4120,  1.7361,  1.8350],\n",
       "         ...,\n",
       "         [-0.6013, -0.0996, -1.2311,  ...,  0.7546,  0.4145,  1.3664],\n",
       "         [-0.0462, -1.6457, -0.6960,  ...,  0.0916,  1.5164, -0.4389],\n",
       "         [-0.1250,  0.7821,  0.5635,  ...,  0.7337,  0.2510,  0.0770]],\n",
       "\n",
       "        [[-0.0462, -1.6457, -0.6960,  ...,  0.0916,  1.5164, -0.4389],\n",
       "         [-0.1250,  0.7821,  0.5635,  ...,  0.7337,  0.2510,  0.0770],\n",
       "         [-0.0047,  0.0795, -0.4560,  ..., -0.2127, -0.5663,  0.3989],\n",
       "         ...,\n",
       "         [-0.5513,  1.9890,  0.8479,  ...,  0.2695, -1.8316,  0.3570],\n",
       "         [-0.0462, -1.6457, -0.6960,  ...,  0.0916,  1.5164, -0.4389],\n",
       "         [-0.1250,  0.7821,  0.5635,  ...,  0.7337,  0.2510,  0.0770]],\n",
       "\n",
       "        [[-0.1250,  0.7821,  0.5635,  ...,  0.7337,  0.2510,  0.0770],\n",
       "         [-1.6470, -1.0362, -0.9711,  ...,  0.3668, -0.3912,  0.1699],\n",
       "         [-1.6470, -1.0362, -0.9711,  ...,  0.3668, -0.3912,  0.1699],\n",
       "         ...,\n",
       "         [-0.6421,  0.8266, -0.3646,  ..., -0.6845,  0.7134,  0.5298],\n",
       "         [-1.6470, -1.0362, -0.9711,  ...,  0.3668, -0.3912,  0.1699],\n",
       "         [-0.6421,  0.8266, -0.3646,  ..., -0.6845,  0.7134,  0.5298]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_embedding_tb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "394c7d4e-c774-4ac2-98d3-48cbeb2d7235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1250,  0.7821,  0.5635,  1.8582,  1.0441, -0.8638,  0.8351, -0.3157,\n",
       "         -1.9776,  0.0179, -1.4129, -1.8791, -0.1798,  0.7904,  0.5239, -0.2694,\n",
       "          1.7093,  0.0579,  0.8637, -0.5890, -1.0340, -0.2179,  0.7987,  0.9105,\n",
       "          0.2691, -0.0366, -0.4808,  0.3163,  0.3866,  0.7337,  0.2510,  0.0770]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_embedding_tb(torch.IntTensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "456e527b-f699-4167-a4b4-1a564ecb2e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "65acab7c-cfe9-4ffb-af2a-7df074d8126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.rand(4,8,5)\n",
    "bb = torch.rand(8,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3560ebc2-7489-41ba-b185-edf6e830827e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9227, 0.5303, 0.1988, 0.9099, 0.7135],\n",
      "         [0.8311, 0.1619, 0.7910, 0.1585, 0.9947],\n",
      "         [0.2882, 0.8013, 0.6001, 0.6325, 0.4233],\n",
      "         [0.7054, 0.2916, 0.0287, 0.3079, 0.8918],\n",
      "         [0.3684, 0.6572, 0.3151, 0.8751, 0.7992],\n",
      "         [0.6765, 0.2444, 0.0914, 0.5188, 0.2067],\n",
      "         [0.9111, 0.0195, 0.7234, 0.9985, 0.7504],\n",
      "         [0.6705, 0.0189, 0.9809, 0.4145, 0.0328]],\n",
      "\n",
      "        [[0.9936, 0.2965, 0.4646, 0.9576, 0.1534],\n",
      "         [0.1463, 0.5813, 0.4331, 0.6152, 0.0806],\n",
      "         [0.5150, 0.2776, 0.2542, 0.0422, 0.7651],\n",
      "         [0.5963, 0.0773, 0.8968, 0.6508, 0.5928],\n",
      "         [0.2064, 0.5754, 0.9818, 0.8429, 0.1106],\n",
      "         [0.9564, 0.5388, 0.7405, 0.8883, 0.9263],\n",
      "         [0.1102, 0.9378, 0.1604, 0.5375, 0.1506],\n",
      "         [0.3904, 0.4773, 0.4402, 0.4210, 0.5394]],\n",
      "\n",
      "        [[0.9932, 0.7905, 0.7797, 0.7001, 0.8871],\n",
      "         [0.4769, 0.5398, 0.6029, 0.0639, 0.0972],\n",
      "         [0.5613, 0.3044, 0.4908, 0.3853, 0.5778],\n",
      "         [0.8253, 0.3342, 0.9004, 0.8948, 0.1163],\n",
      "         [0.1139, 0.0955, 0.2260, 0.3054, 0.4624],\n",
      "         [0.3784, 0.2474, 0.3412, 0.3191, 0.9905],\n",
      "         [0.3147, 0.1420, 0.7078, 0.4711, 0.8828],\n",
      "         [0.8124, 0.9594, 0.1338, 0.8214, 0.9196]],\n",
      "\n",
      "        [[0.2531, 0.9596, 0.8748, 0.5055, 0.7411],\n",
      "         [0.3252, 0.0639, 0.6264, 0.6491, 0.1732],\n",
      "         [0.7425, 0.0729, 0.9303, 0.9842, 0.6361],\n",
      "         [0.1863, 0.7433, 0.5852, 0.6360, 0.6643],\n",
      "         [0.8807, 0.2851, 0.3875, 0.6364, 0.5545],\n",
      "         [0.9032, 0.2374, 0.4818, 0.5934, 0.3672],\n",
      "         [0.8409, 0.5547, 0.0379, 0.4458, 0.2732],\n",
      "         [0.5486, 0.4419, 0.0040, 0.4089, 0.4521]]])\n",
      "tensor([[0.3526, 0.9594, 0.3909, 0.8212, 0.6239],\n",
      "        [0.0779, 0.6175, 0.9144, 0.1729, 0.1768],\n",
      "        [0.9894, 0.9018, 0.2211, 0.8009, 0.4360],\n",
      "        [0.0070, 0.5376, 0.6615, 0.3500, 0.6739],\n",
      "        [0.0724, 0.8465, 0.9263, 0.7757, 0.5847],\n",
      "        [0.6647, 0.1382, 0.3751, 0.4523, 0.2218],\n",
      "        [0.1307, 0.8363, 0.8393, 0.0459, 0.6591],\n",
      "        [0.7034, 0.9750, 0.7893, 0.9597, 0.3363]])\n",
      "tensor([[[1.2753, 1.4897, 0.5897, 1.7311, 1.3374],\n",
      "         [0.9090, 0.7794, 1.7053, 0.3314, 1.1716],\n",
      "         [1.2776, 1.7030, 0.8212, 1.4334, 0.8594],\n",
      "         [0.7124, 0.8292, 0.6903, 0.6579, 1.5657],\n",
      "         [0.4408, 1.5037, 1.2414, 1.6508, 1.3840],\n",
      "         [1.3412, 0.3826, 0.4665, 0.9711, 0.4284],\n",
      "         [1.0418, 0.8558, 1.5628, 1.0444, 1.4095],\n",
      "         [1.3739, 0.9939, 1.7702, 1.3741, 0.3691]],\n",
      "\n",
      "        [[1.3461, 1.2559, 0.8555, 1.7788, 0.7773],\n",
      "         [0.2242, 1.1988, 1.3474, 0.7881, 0.2575],\n",
      "         [1.5044, 1.1794, 0.4752, 0.8431, 1.2011],\n",
      "         [0.6034, 0.6148, 1.5583, 1.0008, 1.2667],\n",
      "         [0.2789, 1.4219, 1.9080, 1.6187, 0.6953],\n",
      "         [1.6211, 0.6770, 1.1155, 1.3406, 1.1480],\n",
      "         [0.2409, 1.7741, 0.9997, 0.5834, 0.8097],\n",
      "         [1.0938, 1.4523, 1.2295, 1.3807, 0.8757]],\n",
      "\n",
      "        [[1.3458, 1.7499, 1.1706, 1.5213, 1.5109],\n",
      "         [0.5549, 1.1572, 1.5173, 0.2369, 0.2740],\n",
      "         [1.5507, 1.2061, 0.7119, 1.1861, 1.0139],\n",
      "         [0.8323, 0.8717, 1.5620, 1.2448, 0.7902],\n",
      "         [0.1863, 0.9420, 1.1523, 1.0811, 1.0471],\n",
      "         [1.0431, 0.3856, 0.7162, 0.7714, 1.2123],\n",
      "         [0.4454, 0.9783, 1.5472, 0.5170, 1.5419],\n",
      "         [1.5158, 1.9343, 0.9231, 1.7811, 1.2559]],\n",
      "\n",
      "        [[0.6056, 1.9190, 1.2657, 1.3267, 1.3649],\n",
      "         [0.4031, 0.6814, 1.5408, 0.8220, 0.3500],\n",
      "         [1.7319, 0.9746, 1.1514, 1.7851, 1.0722],\n",
      "         [0.1933, 1.2809, 1.2468, 0.9860, 1.3383],\n",
      "         [0.9531, 1.1316, 1.3138, 1.4121, 1.1392],\n",
      "         [1.5679, 0.3756, 0.8569, 1.0457, 0.5890],\n",
      "         [0.9715, 1.3910, 0.8772, 0.4917, 0.9323],\n",
      "         [1.2520, 1.4169, 0.7933, 1.3686, 0.7884]]])\n"
     ]
    }
   ],
   "source": [
    "print(aa)\n",
    "print(bb)\n",
    "print(aa+bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3a815471-30eb-46ca-b43b-d47f4a689f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b']\n"
     ]
    }
   ],
   "source": [
    "aaa = ['b' for _ in range(10)]\n",
    "print(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17d340-2865-4eb0-ab81-74277057a29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
